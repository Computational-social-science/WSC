{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成评估指标excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from collections import Counter\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/liujunhui/workspace/proj/semantic_uncertainty/semantic_uncertainty\")\n",
    "\n",
    "import argparse\n",
    "from uncertainty.utils import utils\n",
    "from uncertainty.uncertainty_measures.semantic_entropy import predictive_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数\n",
    "args = argparse.Namespace(\n",
    "    dataset=\"trivia_qa\",\n",
    "    model_name=\"Llama-2-7b-chat-8bit\",\n",
    "    model_max_new_tokens=512,\n",
    "    debug=False,\n",
    "    entity=None,\n",
    "    random_seed=10,\n",
    "    metric='squad',\n",
    "    compute_accuracy_at_all_temps=True,\n",
    "    experiment_lot='Unnamed Experiment',\n",
    "    recompute_accuracy=False,\n",
    "    train_wandb_runid=None,\n",
    "    num_eval_samples=10000000000000000000,\n",
    "    compute_predictive_entropy=True,\n",
    "    compute_p_ik=True,\n",
    "    compute_p_ik_answerable=False,\n",
    "    compute_context_entails_response=False,\n",
    "    analyze_run=True,\n",
    "    assign_new_wandb_id=False,\n",
    "    restore_entity_eval=None,\n",
    "    restore_entity_train=None,\n",
    "    condition_on_question=True,\n",
    "    strict_entailment=True,\n",
    "    use_all_generations=True,\n",
    "    use_num_generations=-1,\n",
    "    entailment_model='deberta',\n",
    "    entailment_cache_id=None,\n",
    "    entailment_cache_only=False,\n",
    "    compute_p_true_in_compute_stage=False,\n",
    "    reuse_entailment_model=False,\n",
    "    use_mc_options=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82fec6d8ac664f9a9d826b0c4523d81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize model.\n",
    "model = utils.init_model(args)\n",
    "# Temperature for first generation is always `0.1`.\n",
    "temperature = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/liujunhui/workspace/models/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf07883eec5048b1b1f5019adb5ffbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n"
     ]
    }
   ],
   "source": [
    "# 香农熵\n",
    "def calculate_entropy(sentence):\n",
    "    # 使用正则表达式分割，匹配空格和换行符\n",
    "    words = re.findall(r'\\w+|\\s|\\n|\\t', sentence.lower())\n",
    "    \n",
    "    # 计算每个单词的频率\n",
    "    word_counts = Counter(words)\n",
    "    # print(word_counts)\n",
    "    total_words = len(words)\n",
    "    \n",
    "    # 计算香农熵\n",
    "    entropy = 0.0\n",
    "    for count in word_counts.values():\n",
    "        p = count / total_words\n",
    "        entropy -= p * math.log2(p)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "# 困惑度\n",
    "def calculate_perplexity(sentence):\n",
    "    entropy = calculate_entropy(sentence)\n",
    "    perplexity = 2 ** entropy\n",
    "    return perplexity\n",
    "\n",
    "# fluency\n",
    "tokenizer_fluency = AutoTokenizer.from_pretrained(\"/home/liujunhui/workspace/models/parrot_fluency_model\")\n",
    "model_fluency = AutoModelForSequenceClassification.from_pretrained(\"/home/liujunhui/workspace/models/parrot_fluency_model\")\n",
    "\n",
    "# toxicity\n",
    "tokenizer_toxicity = AutoTokenizer.from_pretrained(\"/home/liujunhui/workspace/models/roberta_toxicity_classifier\")\n",
    "model_toxicity = AutoModelForSequenceClassification.from_pretrained(\"/home/liujunhui/workspace/models/roberta_toxicity_classifier\")\n",
    "\n",
    "# semantic_similarity\n",
    "#  device_map='auto'\n",
    "model_semantic_similarity = AutoModel.from_pretrained('/home/css/models/NV-Embed-v2', trust_remote_code=True, device_map='auto')\n",
    "\n",
    "def analyze_fluency(sentence):\n",
    "\n",
    "    inputs = tokenizer_fluency(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model_fluency(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    fluency_score = torch.softmax(logits, dim=1)[0][1].item()\n",
    "\n",
    "    return fluency_score\n",
    "\n",
    "def analyze_toxicity(sentence):\n",
    "\n",
    "    inputs = tokenizer_toxicity(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model_toxicity(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    toxicity_score = torch.softmax(logits, dim=1)[0][1].item()\n",
    "\n",
    "    return toxicity_score\n",
    "\n",
    "\n",
    "def calculate_semantic_similarity(sentence1, sentence2, max_length=32768):\n",
    "\n",
    "    embeddings = model_semantic_similarity.encode([sentence1, sentence2], instruction=\"\", max_length=max_length)\n",
    "    \n",
    "    similarity = cos_sim(embeddings[0], embeddings[1])\n",
    "    \n",
    "    return similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original文本文件路径\n",
    "file_path_1 = \"/home/liujunhui/workspace/proj/WSC/dataset/jfleg/jfleg/sources.txt\"\n",
    "file_path_2 = \"/home/liujunhui/workspace/proj/WSC/dataset/jfleg/jfleg/corrections.txt\"\n",
    "# 打开文件并读取内容到列表\n",
    "with open(file_path_1, \"r\") as file:\n",
    "    jfleg_lst = [line.strip() for line in file.readlines()]\n",
    "\n",
    "with open(file_path_2, \"r\") as file:\n",
    "    jfleg_lst.extend([line.strip() for line in file.readlines()])\n",
    "\n",
    "file_path_3 = \"/home/liujunhui/workspace/proj/WSC/dataset/jfleg/jfleg_corrected/sources.txt\"\n",
    "file_path_4 = \"/home/liujunhui/workspace/proj/WSC/dataset/jfleg/jfleg_corrected/corrections.txt\"\n",
    "\n",
    "# 打开文件并读取内容到列表\n",
    "with open(file_path_3, \"r\") as file:\n",
    "    jfleg_lst_wsc = [line.strip() for line in file.readlines()]\n",
    "\n",
    "with open(file_path_4, \"r\") as file:\n",
    "    jfleg_lst_wsc.extend([line.strip() for line in file.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3202\n",
      "3202\n"
     ]
    }
   ],
   "source": [
    "print(len(jfleg_lst))\n",
    "print(len(jfleg_lst_wsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208c0a00ce764a83af3ebb4943adc223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liujunhui/.cache/huggingface/modules/transformers_modules/NV-Embed-v2/modeling_nvembed.py:349: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'input_ids': torch.tensor(batch_dict.get('input_ids').to(batch_dict.get('input_ids')).long()),\n",
      "/home/liujunhui/miniconda3/envs/semantic_uncertainty/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    }
   ],
   "source": [
    "flu_lst=[]\n",
    "tox_lst=[]\n",
    "entropy_lst=[]\n",
    "ppl_lst=[]\n",
    "ss_lst=[]\n",
    "semantic_entropy_lst=[]\n",
    "\n",
    "for i in tqdm(range(len(jfleg_lst))):\n",
    "\n",
    "    ori_text = jfleg_lst[i]\n",
    "    cor_text = jfleg_lst_wsc[i]\n",
    "\n",
    "    flu_lst.append(analyze_fluency(cor_text)-analyze_fluency(ori_text))\n",
    "    tox_lst.append(analyze_toxicity(cor_text)-analyze_toxicity(ori_text))\n",
    "    entropy_lst.append(calculate_entropy(cor_text)-calculate_entropy(ori_text))\n",
    "    ppl_lst.append(calculate_perplexity(cor_text)-calculate_perplexity(ori_text))\n",
    "    ss_lst.append(calculate_semantic_similarity(ori_text,cor_text))\n",
    "    semantic_entropy_lst.append(predictive_entropy(model.get_token_log_likelihoods(cor_text)) -\n",
    "                                 predictive_entropy(model.get_token_log_likelihoods(ori_text)))\n",
    "\n",
    "# 创建一个包含这四个列表的字典\n",
    "data = {\n",
    "    'ori_text':jfleg_lst,\n",
    "    'cor_text':jfleg_lst_wsc,\n",
    "    'fluency': flu_lst,\n",
    "    'toxicity': tox_lst,\n",
    "    'Shannon entropy':entropy_lst,\n",
    "    'perplexity': ppl_lst,\n",
    "    'semantic entropy':semantic_entropy_lst,\n",
    "    'semantic similarity':ss_lst\n",
    "}\n",
    "\n",
    "# 将字典转换为DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ori_text</th>\n",
       "      <th>cor_text</th>\n",
       "      <th>fluency</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>shannon_entropy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>semantic_entropy</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So I think we would not be live if our ancesto...</td>\n",
       "      <td>So I think we would not belive if our ancestor...</td>\n",
       "      <td>0.302740</td>\n",
       "      <td>5.091497e-07</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>0.079090</td>\n",
       "      <td>0.540797</td>\n",
       "      <td>0.858357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Imagine yourself you are working in factory ju...</td>\n",
       "      <td>Imagine yourself you are working in factory ju...</td>\n",
       "      <td>-0.004786</td>\n",
       "      <td>-4.645365e-04</td>\n",
       "      <td>0.062624</td>\n",
       "      <td>0.463773</td>\n",
       "      <td>0.044193</td>\n",
       "      <td>0.980495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For example , they can play football whenever ...</td>\n",
       "      <td>For example, they can play football whenever t...</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>-8.590570e-06</td>\n",
       "      <td>0.202850</td>\n",
       "      <td>0.941190</td>\n",
       "      <td>0.668214</td>\n",
       "      <td>0.877560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>While It is true that consumers preffer to buy...</td>\n",
       "      <td>While It is true that consumers preffer to buy...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.936774e-07</td>\n",
       "      <td>0.083739</td>\n",
       "      <td>0.691510</td>\n",
       "      <td>0.138582</td>\n",
       "      <td>0.980103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And young people spend more time on ther lifes...</td>\n",
       "      <td>And young people spend more time on ther lifes...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.362009e-07</td>\n",
       "      <td>0.090736</td>\n",
       "      <td>0.389478</td>\n",
       "      <td>0.167218</td>\n",
       "      <td>0.959664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>The person takes the bike , goes where he wish...</td>\n",
       "      <td>The person takes the bike, goes where he wishe...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.817902e-06</td>\n",
       "      <td>0.108515</td>\n",
       "      <td>0.582923</td>\n",
       "      <td>0.483987</td>\n",
       "      <td>0.925970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>And I am going to another country .</td>\n",
       "      <td>And I am going to another country.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.797158e-05</td>\n",
       "      <td>0.103703</td>\n",
       "      <td>0.394363</td>\n",
       "      <td>0.807210</td>\n",
       "      <td>0.978307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>The youth today are aware of their responsibil...</td>\n",
       "      <td>The youth today are aware of their responsibil...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.850218e-07</td>\n",
       "      <td>0.085420</td>\n",
       "      <td>0.385776</td>\n",
       "      <td>0.110892</td>\n",
       "      <td>0.966446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>But I disagree with this opinion because often...</td>\n",
       "      <td>But I disagree with this opinion because often...</td>\n",
       "      <td>0.247741</td>\n",
       "      <td>8.938405e-07</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.131764</td>\n",
       "      <td>0.364977</td>\n",
       "      <td>0.957427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>it gives him many opportunities in life , and ...</td>\n",
       "      <td>it gives him many opportunities in life, and i...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.718866e-06</td>\n",
       "      <td>0.077833</td>\n",
       "      <td>0.574733</td>\n",
       "      <td>0.397434</td>\n",
       "      <td>0.977411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3202 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ori_text  \\\n",
       "0     So I think we would not be live if our ancesto...   \n",
       "1     Imagine yourself you are working in factory ju...   \n",
       "2     For example , they can play football whenever ...   \n",
       "3     While It is true that consumers preffer to buy...   \n",
       "4     And young people spend more time on ther lifes...   \n",
       "...                                                 ...   \n",
       "3197  The person takes the bike , goes where he wish...   \n",
       "3198                And I am going to another country .   \n",
       "3199  The youth today are aware of their responsibil...   \n",
       "3200  But I disagree with this opinion because often...   \n",
       "3201  it gives him many opportunities in life , and ...   \n",
       "\n",
       "                                               cor_text   fluency  \\\n",
       "0     So I think we would not belive if our ancestor...  0.302740   \n",
       "1     Imagine yourself you are working in factory ju... -0.004786   \n",
       "2     For example, they can play football whenever t...  0.002559   \n",
       "3     While It is true that consumers preffer to buy...  0.000000   \n",
       "4     And young people spend more time on ther lifes...  0.000000   \n",
       "...                                                 ...       ...   \n",
       "3197  The person takes the bike, goes where he wishe...  0.000000   \n",
       "3198                 And I am going to another country.  0.000000   \n",
       "3199  The youth today are aware of their responsibil...  0.000000   \n",
       "3200  But I disagree with this opinion because often...  0.247741   \n",
       "3201  it gives him many opportunities in life, and i...  0.000000   \n",
       "\n",
       "          toxicity  shannon_entropy  perplexity  semantic_entropy  \\\n",
       "0     5.091497e-07         0.014341    0.079090          0.540797   \n",
       "1    -4.645365e-04         0.062624    0.463773          0.044193   \n",
       "2    -8.590570e-06         0.202850    0.941190          0.668214   \n",
       "3     4.936774e-07         0.083739    0.691510          0.138582   \n",
       "4     4.362009e-07         0.090736    0.389478          0.167218   \n",
       "...            ...              ...         ...               ...   \n",
       "3197  2.817902e-06         0.108515    0.582923          0.483987   \n",
       "3198 -2.797158e-05         0.103703    0.394363          0.807210   \n",
       "3199 -3.850218e-07         0.085420    0.385776          0.110892   \n",
       "3200  8.938405e-07         0.017884    0.131764          0.364977   \n",
       "3201  3.718866e-06         0.077833    0.574733          0.397434   \n",
       "\n",
       "      semantic_similarity  \n",
       "0                0.858357  \n",
       "1                0.980495  \n",
       "2                0.877560  \n",
       "3                0.980103  \n",
       "4                0.959664  \n",
       "...                   ...  \n",
       "3197             0.925970  \n",
       "3198             0.978307  \n",
       "3199             0.966446  \n",
       "3200             0.957427  \n",
       "3201             0.977411  \n",
       "\n",
       "[3202 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存DataFrame到Excel文件\n",
    "excel_file_path = 'jfleg_data_all.xlsx'  # 输出的Excel文件路径\n",
    "df.to_excel(excel_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(\"jfleg_data_all.xlsx\")\n",
    "# df = df.rename(columns={'shannon_entropy': 'Shannon entropy','semantic_similarity':'semantic similarity','semantic_entropy':'semantic entropy'})\n",
    "# excel_file_path = 'jfleg_data_all.xlsx'  # 输出的Excel文件路径\n",
    "# df.to_excel(excel_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic_uncertainty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
