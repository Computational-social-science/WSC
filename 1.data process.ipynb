{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whitespace_correction import WhitespaceCorrector\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 09:22:29,979 [WHITESPACE CORRECTION DOWNLOAD] [INFO] eo_larger_byte is already downloaded to download directory /home/css/models/wsc\n",
      "/home/liujunhui/miniconda3/envs/semantic_uncertainty/lib/python3.11/site-packages/text_utils/io.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_path, map_location=device)\n",
      "2024-11-26 09:22:31,207 [WHITESPACE CORRECTION] [INFO] running eo_huge_byte whitespace corrector on device NVIDIA GeForce RTX 4090 (24,217MiB memory, 8.9 compute capability, 128 multiprocessors)\n"
     ]
    }
   ],
   "source": [
    "cor = WhitespaceCorrector.from_pretrained(model=\"eo_larger_byte\", device=\"cuda:0\", download_dir=\"/home/css/models/wsc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 文件格式转换\n",
    "import json\n",
    "\n",
    "data_path_1 = \"/home/liujunhui/workspace/proj/WSC/dataset/jfleg_txt/jfleg/sources.txt\"\n",
    "data_path_2 = \"/home/liujunhui/workspace/proj/WSC/dataset/jfleg_txt/jfleg/corrections.txt\"\n",
    "# 打开文件并读取内容到列表\n",
    "with open(data_path_1, \"r\") as file:\n",
    "    lst_1 = [line.strip() for line in file.readlines()]\n",
    "\n",
    "with open(data_path_2, \"r\") as file:\n",
    "    lst_2 = [line.strip() for line in file.readlines()]\n",
    "\n",
    "dic = {\n",
    "    \"original\":lst_1 + lst_2\n",
    "}\n",
    "\n",
    "# 转换文件格式为json,保存为json格式\n",
    "with open(\"dataset/jfleg.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dic, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取json文件，获取original 文本，进行wsc纠正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c028e580f27e40ecb4b8152f9daba70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liujunhui/miniconda3/envs/semantic_uncertainty/lib/python3.11/site-packages/text_utils/modules/grouping.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(enabled=False):\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset/jfleg.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "lst_original = data['original']\n",
    "\n",
    "lst_wsc = []\n",
    "for item in tqdm(lst_original):\n",
    "    corrected_string = cor.correct_text(item)\n",
    "    lst_wsc.append(corrected_string)\n",
    "\n",
    "\n",
    "# 保存wsc后的数据\n",
    "dic = {\n",
    "    \"original\":lst_original,\n",
    "    \"wsc\":lst_wsc\n",
    "}\n",
    "with open(\"dataset/jfleg.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dic, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 单独保存下游任务需要的txt文件\n",
    "mid = len(lst_wsc) // 2\n",
    "wsc_1=lst_wsc[:mid]\n",
    "wsc_2=lst_wsc[mid:]\n",
    "with open(\"dataset/jfleg_txt/jfleg_corrected/sources.txt\", \"w\") as file:\n",
    "    for i, line in enumerate(wsc_1):\n",
    "        if i < len(wsc_1) - 1:\n",
    "            file.write(line + \"\\n\")\n",
    "        else:\n",
    "            file.write(line)\n",
    "\n",
    "with open(\"dataset/jfleg_txt/jfleg_corrected/corrections.txt\", \"w\") as file:\n",
    "    for i, line in enumerate(wsc_2):\n",
    "        if i < len(wsc_2) - 1:\n",
    "            file.write(line + \"\\n\")\n",
    "        else:\n",
    "            file.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic_uncertainty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
