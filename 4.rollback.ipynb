{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "from sentence_transformers.util import cos_sim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6089c5edb9944a8b80f025161f329db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n"
     ]
    }
   ],
   "source": [
    "model_semantic_similarity = AutoModel.from_pretrained('/home/css/models/NV-Embed-v2', \n",
    "                                                      trust_remote_code=True, \n",
    "                                                      device_map=\"auto\",\n",
    "                                                      torch_dtype='bfloat16',\n",
    "                                                      )\n",
    "\n",
    "def calculate_semantic_similarity(sentence1, sentence2, max_length=32768):\n",
    "    # 对输入的两个句子进行编码\n",
    "    embeddings = model_semantic_similarity.encode([sentence1, sentence2], \n",
    "                                                  instruction=\"\", \n",
    "                                                  max_length=max_length)\n",
    "    \n",
    "    # 计算余弦相似度\n",
    "    similarity = cos_sim(embeddings[0], embeddings[1])\n",
    "    \n",
    "    return similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a261c0307c0042bba69979c3209f0ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liujunhui/.cache/huggingface/modules/transformers_modules/NV-Embed-v2/modeling_nvembed.py:349: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'input_ids': torch.tensor(batch_dict.get('input_ids').to(batch_dict.get('input_ids')).long()),\n",
      "/home/liujunhui/miniconda3/envs/semantic_uncertainty/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.9426\n",
    "\n",
    "with open(\"dataset/jfleg.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "lst_original = data['original']\n",
    "lst_wsc = data['wsc']\n",
    "\n",
    "lst_rollback = []\n",
    "for i, item in tqdm(enumerate(lst_original), total=len(lst_original)):\n",
    "    ori_text = item\n",
    "    cor_text = lst_wsc[i]\n",
    "    if calculate_semantic_similarity(ori_text, cor_text) < threshold:\n",
    "        lst_rollback.append(ori_text)\n",
    "    else:\n",
    "        lst_rollback.append(cor_text)\n",
    "\n",
    "# 保存wsc后的数据\n",
    "dic = {\n",
    "    \"original\":lst_original,\n",
    "    \"wsc\":lst_wsc,\n",
    "    \"rollback\":lst_rollback\n",
    "}\n",
    "with open(\"dataset/jfleg.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dic, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 单独保存下游任务需要的txt文件\n",
    "mid = len(lst_rollback) // 2\n",
    "rollback_1=lst_rollback[:mid]\n",
    "rollback_2=lst_rollback[mid:]\n",
    "with open(\"dataset/jfleg_txt/jfleg_rollback/sources.txt\", \"w\") as file:\n",
    "    for i, line in enumerate(rollback_1):\n",
    "        if i < len(rollback_1) - 1:\n",
    "            file.write(line + \"\\n\")\n",
    "        else:\n",
    "            file.write(line)\n",
    "\n",
    "with open(\"dataset/jfleg_txt/jfleg_rollback/corrections.txt\", \"w\") as file:\n",
    "    for i, line in enumerate(rollback_2):\n",
    "        if i < len(rollback_2) - 1:\n",
    "            file.write(line + \"\\n\")\n",
    "        else:\n",
    "            file.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic_uncertainty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
